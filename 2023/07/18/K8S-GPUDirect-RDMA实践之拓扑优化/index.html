<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="&#34;auto&#34;"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png"><link rel="icon" type="image/png" href="/img/favicon.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="description" content=""><meta name="author" content="maao"><meta name="keywords" content=""><title>K8S GPUDirect RDMA实践之拓扑优化 - MAAO的博客</title><link rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css"><link rel="stylesheet" href="/lib/hint/hint.min.css"><link rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/10.0.0/styles/darcula.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_pf9vaxs7x7b.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css"><link rel="stylesheet" href="/css/main.css"><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><meta name="generator" content="Hexo 5.1.1"></head><body><header style="height:70vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"> <a class="navbar-brand" href="/">&nbsp;<strong>maao's space</strong>&nbsp;</a> <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> 首页</a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> 归档</a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> 分类</a></li><li class="nav-item"><a class="nav-link" href="/tags/"><i class="iconfont icon-tags-fill"></i> 标签</a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> 关于</a></li><li class="nav-item" id="search-btn"> <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;<i class="iconfont icon-search"></i>&nbsp;</a></li><li class="nav-item" id="color-toggle-btn"> <a class="nav-link" href="javascript:">&nbsp;<i class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a></li></ul></div></div></nav><div class="banner intro-2" id="background" parallax="true" style="background:url(/img/default.jpg) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="container page-header text-center fade-in-up"> <span class="h2" id="subtitle">K8S GPUDirect RDMA实践之拓扑优化</span><div class="mt-3"><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2023-07-18 16:11" pubdate>2023年7月18日 下午</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 2.4k 字</span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 35 分钟</span><span id="leancloud-post-views-container" class="post-meta" style="display:none"><i class="iconfont icon-eye" aria-hidden="true"></i><span id="leancloud-post-views"></span> 次</span></div></div></div></div></div></header><main><div class="container-fluid"><div class="row"><div class="d-none d-lg-block col-lg-2"></div><div class="col-lg-8 nopadding-md"><div class="container nopadding-md" id="board-ctn"><div class="py-5" id="board"><article class="post-content mx-auto" id="post"><h1 style="display:none">K8S GPUDirect RDMA实践之拓扑优化</h1><div class="markdown-body" id="post-body"><p>NVIDIA GPUDirect RDMA(gdr)是一种能让第三方PCI Express设备通过bypass CPU直接访问GPU的技术，NVIDIA有一个在Kubernetes上使用GPUDirect RDMA技术的方案，但由于拓扑原因，做不到最优的性能。<br>目前没有找到可以直接使用的方案，记录下调研的结果。</p><a id="more"></a><h2 id="K8S中使用gdr"><a href="#K8S中使用gdr" class="headerlink" title="K8S中使用gdr"></a>K8S中使用gdr</h2><p>官方文档如下，就不细说了：</p><ul><li><a target="_blank" rel="noopener" href="https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/gpu-operator-rdma.html">GPUDirect RDMA and GPUDirect Storage</a></li><li><a target="_blank" rel="noopener" href="https://developer.nvidia.com/blog/deploying-gpudirect-rdma-on-egx-stack-with-the-network-operator/">Deploying GPUDirect RDMA on the EGX Stack with the NVIDIA Network Operator</a></li></ul><p>主要是使用官方的GPU Operator与Network Operator，为容器分配GPU与RDMA网卡，依赖NVIDIA peer memory driver、MOFED driver，实现在Pod中使用gdr。</p><p>但是在<a target="_blank" rel="noopener" href="https://developer.nvidia.com/blog/deploying-gpudirect-rdma-on-egx-stack-with-the-network-operator/">Deploying GPUDirect RDMA on the EGX Stack with the NVIDIA Network Operator</a> 文章中有这么一段话：</p><blockquote><p>The RDMA sample Pods do not enforce NUMA alignment between the GPU, network controller, and the Pod CPU socket. Performance can vary across runs, depending on which resources are presented to the Pod.</p></blockquote><p>也就是说gdr的性能依赖于Pod所分配的GPU、RDMA网卡、CPU的物理拓扑，比如是不是一个NUMA。</p><h2 id="拓扑与性能"><a href="#拓扑与性能" class="headerlink" title="拓扑与性能"></a>拓扑与性能</h2><p>关于具体的拓扑与性能关系的介绍，在官方文档<a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/gpudirect-rdma/index.html">GPUDirect RDMA</a>中有描述：</p><blockquote><p>Even though the only theoretical requirement for GPUDirect RDMA to work between a third-party device and an NVIDIA GPU is that they share the same root complex, there exist bugs (mostly in chipsets) causing it to perform badly, or not work at all in certain setups.</p><p>We can distinguish between three situations, depending on what is on the path between the GPU and the third-party device:</p><ul><li>PCIe switches only</li><li>single CPU/IOH</li><li>CPU/IOH &lt;-&gt; QPI/HT &lt;-&gt; CPU/IOH</li></ul><p>The first situation, where there are only PCIe switches on the path, is optimal and yields the best performance. The second one, where a single CPU/IOH is involved, works, but yields worse performance ( especially peer-to-peer read bandwidth has been shown to be severely limited on some processor architectures ). Finally, the third situation, where the path traverses a QPI/HT link, may be extremely performance-limited or even not work reliably.</p></blockquote><p>可知，当只经过PCIe Switch的时候，性能最好；如果经过CPU，性能较差；如果跨NUMA的时候，性能最差，甚至不可用。</p><p>从<a target="_blank" rel="noopener" href="https://github.com/NVIDIA/nccl">NVIDIA/nccl</a>库中也可以看出这一点。nccl判断设备路径是否支持gdr的函数为<code>ncclTopoCheckGdr()</code>，除了判断GPU与NIC是否支持gdr外，还需要两者之间距离不能大于<code>PATH_PXB</code>，而<code>PATH_PXB</code>在nccl建立的拓扑中，表示路径最多经过了多个PCIe Switch。</p><div class="hljs"><pre><code class="hljs c"><span class="hljs-function">ncclResult_t <span class="hljs-title">ncclTopoCheckGdr</span><span class="hljs-params">(struct ncclTopoSystem* system, <span class="hljs-keyword">int64_t</span> busId, <span class="hljs-keyword">int</span> netDev, <span class="hljs-keyword">int</span> read, <span class="hljs-keyword">int</span>* useGdr)</span> </span>&#123;
  *useGdr = <span class="hljs-number">0</span>;

  <span class="hljs-comment">// Get GPU and NET</span>
  <span class="hljs-keyword">int</span> n, g;
  NCCLCHECK(ncclTopoIdToIndex(system, NET, netDev, &amp;n));
  <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">ncclTopoNode</span>* <span class="hljs-title">net</span> = <span class="hljs-title">system</span>-&gt;<span class="hljs-title">nodes</span>[<span class="hljs-title">NET</span>].<span class="hljs-title">nodes</span>+<span class="hljs-title">n</span>;</span>
  NCCLCHECK(ncclTopoIdToIndex(system, GPU, busId, &amp;g));
  <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">ncclTopoNode</span>* <span class="hljs-title">gpu</span> = <span class="hljs-title">system</span>-&gt;<span class="hljs-title">nodes</span>[<span class="hljs-title">GPU</span>].<span class="hljs-title">nodes</span>+<span class="hljs-title">g</span>;</span>

  <span class="hljs-comment">// Check that both the NIC and GPUs support it</span>
  <span class="hljs-comment">// 先检测net、gpu支持gdr</span>
  <span class="hljs-keyword">if</span> (net-&gt;net.gdrSupport == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> ncclSuccess;
  <span class="hljs-keyword">if</span> (gpu-&gt;gpu.gdrSupport == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> ncclSuccess;

  <span class="hljs-keyword">if</span> (read) &#123; <span class="hljs-comment">// For reads (sends) only enable under certain conditions</span>
    <span class="hljs-keyword">int</span> gdrReadParam = ncclParamNetGdrRead();
    <span class="hljs-keyword">if</span> (gdrReadParam == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> ncclSuccess;
    <span class="hljs-keyword">if</span> (gdrReadParam &lt; <span class="hljs-number">0</span>) &#123;
      <span class="hljs-keyword">int</span> nvlink = <span class="hljs-number">0</span>;
      <span class="hljs-comment">// Since we don&#x27;t know whether there are other communicators,</span>
      <span class="hljs-comment">// it&#x27;s better to keep things local if we have a single GPU.</span>
      <span class="hljs-keyword">if</span> (system-&gt;nodes[GPU].count == <span class="hljs-number">1</span>) nvlink = <span class="hljs-number">1</span>;
      <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i=<span class="hljs-number">0</span>; i&lt;system-&gt;nodes[GPU].count; i++) &#123;
        <span class="hljs-keyword">if</span> (i == g) <span class="hljs-keyword">continue</span>;
        <span class="hljs-keyword">if</span> (gpu-&gt;paths[GPU][i].type == PATH_NVL) &#123;
          nvlink = <span class="hljs-number">1</span>;
          <span class="hljs-keyword">break</span>;
        &#125;
      &#125;
      <span class="hljs-keyword">if</span> (!nvlink) <span class="hljs-keyword">return</span> ncclSuccess;
    &#125;
  &#125;

  <span class="hljs-comment">// Check if we are close enough that it makes sense to enable GDR</span>
  <span class="hljs-keyword">int</span> netGdrLevel = PATH_PXB;
  NCCLCHECK(ncclGetLevel(&amp;ncclTopoUserGdrLevel, <span class="hljs-literal">NULL</span>, <span class="hljs-string">&quot;NCCL_NET_GDR_LEVEL&quot;</span>));
  <span class="hljs-keyword">if</span> (ncclTopoUserGdrLevel != <span class="hljs-number">-2</span>) netGdrLevel = ncclTopoUserGdrLevel;
  <span class="hljs-keyword">int</span> distance = gpu-&gt;paths[NET][n].type;
  <span class="hljs-keyword">if</span> (distance == PATH_PXN) &#123;
    <span class="hljs-comment">// In case of PXN, use the intermediate GPU distance instead</span>
    <span class="hljs-keyword">int</span> proxyRank, g;
    NCCLCHECK(ncclTopoGetIntermediateRank(system, gpu-&gt;gpu.rank, netDev, &amp;proxyRank));
    NCCLCHECK(ncclTopoRankToIndex(system, proxyRank, &amp;g));
    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">ncclTopoNode</span>* <span class="hljs-title">proxyGpu</span> = <span class="hljs-title">system</span>-&gt;<span class="hljs-title">nodes</span>[<span class="hljs-title">GPU</span>].<span class="hljs-title">nodes</span>+<span class="hljs-title">g</span>;</span>
    distance = proxyGpu-&gt;paths[NET][n].type;
  &#125;
  <span class="hljs-comment">// 还需要路径上不超过PATH_PXB</span>
  <span class="hljs-keyword">if</span> (distance &gt; netGdrLevel) &#123;
    INFO(NCCL_NET,<span class="hljs-string">&quot;GPU Direct RDMA Disabled for GPU %lx / HCA %d (distance %d &gt; %d)&quot;</span>, busId, netDev, distance, netGdrLevel);
    <span class="hljs-keyword">return</span> ncclSuccess;
  &#125;

  *useGdr = <span class="hljs-number">1</span>;
  INFO(NCCL_NET,<span class="hljs-string">&quot;GPU Direct RDMA Enabled for GPU %lx / HCA %d (distance %d &lt;= %d), read %d&quot;</span>, busId, netDev, distance, netGdrLevel, read);
  <span class="hljs-keyword">return</span> ncclSuccess;
&#125;</code></pre></div><p>nccl里拓扑的路径类型：</p><div class="hljs"><pre><code class="hljs c"><span class="hljs-comment">// Local (myself)</span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> PATH_LOC 0</span>
<span class="hljs-comment">// Connection traversing NVLink</span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> PATH_NVL 1</span>
<span class="hljs-comment">// Connection through NVLink using an intermediate GPU</span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> PATH_NVB 2</span>
<span class="hljs-comment">// Connection traversing at most a single PCIe bridge</span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> PATH_PIX 3</span>
<span class="hljs-comment">// Connection traversing multiple PCIe bridges (without traversing the PCIe Host Bridge)</span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> PATH_PXB 4</span>
<span class="hljs-comment">// Connection between a GPU and a NIC using an intermediate GPU. Used to enable rail-local, aggregated network send/recv operations.</span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> PATH_PXN 5</span>
<span class="hljs-comment">// Connection traversing PCIe as well as a PCIe Host Bridge (typically the CPU)</span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> PATH_PHB 6</span>
<span class="hljs-comment">// Connection traversing PCIe as well as the SMP interconnect between NUMA nodes (e.g., QPI/UPI)</span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> PATH_SYS 7</span>
<span class="hljs-comment">// Connection through the network</span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> PATH_NET 8</span>
<span class="hljs-comment">// Disconnected</span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> PATH_DIS 9</span></code></pre></div><p>由此可见，在给Pod分配RDMA网卡与GPU时，最好的情况是RDMA网卡与GPU只经过多个或一个PCIe Switch。</p><h2 id="Kubelet-TopologyManager"><a href="#Kubelet-TopologyManager" class="headerlink" title="Kubelet TopologyManager"></a>Kubelet TopologyManager</h2><p>NVIDIA的GPU Operator与Network Operator都是通过部署Device Plugin来管理、分配设备的，两个Operator分别会部署NVIDIA的k8s device plugin（管理GPU）以及RDMA share device plugin（管理RDMA网卡，和部署模式有关，也有可能是SR-IOV device plugin）。</p><p>在K8s中，通过Kubelet TopologyManager来实现NUMA对齐，目前Kubelet TopologyManager包含CPUManager、DeviceManager、MemoryManager，能实现Device资源、CPU、Memory分配在同一个NUMA下。</p><p>具体的，Kubelet会先通过Device Plugin的<code>ListAndWatch()</code>获取设备列表，返回的<code>Device</code>中，会有<code>Topology</code>字段用于设置设备的拓扑，Kubelet在为Pod分配资源时，会根据设定的策略，强制或尽量地选择与CPU相同NUMA的Device。</p><div class="hljs"><pre><code class="hljs go"><span class="hljs-keyword">type</span> Device <span class="hljs-keyword">struct</span> &#123;
	...
	<span class="hljs-comment">// Topology for device</span>
	Topology             *TopologyInfo <span class="hljs-string">`protobuf:&quot;bytes,3,opt,name=topology,proto3&quot; json:&quot;topology,omitempty&quot;`</span>
	...
&#125;
<span class="hljs-keyword">type</span> TopologyInfo <span class="hljs-keyword">struct</span> &#123;
	Nodes                []*NUMANode
	...
&#125;</code></pre></div><p>除此外，Device Plugin还可以实现<code>GetPreferredAllocation()</code>接口，在Kubelet选出与CPU相同NUMA的多个device后，Kubelet会调用Device Plugin的<code>GetPreferredAllocation()</code>接口，让Device Plugin进行进一步的优选。</p><p>而在NVIDIA方案中的几个Device Plugin，都没有实现<code>GetPreferredAllocation()</code>接口，也就是说在NVIDIA的K8s GPUDirect RDMA方案中，最多只能通过Kubelet的TopologyManager来保证NUMA的对齐，但无法保证能达到推荐的<code>PCIe switches only</code>的性能。</p><h2 id="Device-Plugin机制的问题"><a href="#Device-Plugin机制的问题" class="headerlink" title="Device Plugin机制的问题"></a>Device Plugin机制的问题</h2><p>实际上，无法单独通过一类资源的<code>GetPreferredAllocation()</code>方法，做到多种资源的亲和性分配。比如当GPU Device Plugin收到kubelet的<code>GetPreferredAllocation()</code>调用后，GPU Device Plugin并不知道它在为哪个Pod分配GPU（<code>Allocate()</code>与<code>GetPreferredAllocation()</code>都只传递DeviceID），也就不知道请求GPU的Pod是否也同时需要分配RDMA，以及RDMA网卡的分配结果了，做不到亲和性分配。</p><p>除此之外，在调度层面不会考虑devices资源的亲和性，仅仅是看节点的device资源数量上是否满足，device的分配都是由kubelet完成的，kubelet只能在本节点层面选择，而有些节点可能无法满足<code>PCIe switches only</code>的分配。</p><h2 id="可能的方案"><a href="#可能的方案" class="headerlink" title="可能的方案"></a>可能的方案</h2><p><a target="_blank" rel="noopener" href="https://developer.aliyun.com/article/1180698">Container Runtime CDI与NRI介绍</a> 这篇文章里介绍了两种方法：<br>1）将Device Plugin的<code>Allocate()</code>功能推到<code>PreStartContainer()</code>里实现，利用CDI可以越过Kubelet device plugin，进行设备的分配。<br>2）通过Kubernetes Schduler Extender实现全局的device资源调度，通过NRI替代device plugin，对容器进行设备的分配、配置。</p><p>第一种方式算是Device Plugin机制的一种另类用法，第二种方式不再依赖Device Plugin机制，而是通过NRI，在容器创建的时候从Pod annotation中获取设备信息（可以由kube-scheduler在调度时写入），Device Plugin在方案中唯一的用处可能只是上报资源状态到Node资源上，在kube-scheduler调度时使用。</p><p>除此外，<a target="_blank" rel="noopener" href="https://github.com/kubernetes/enhancements/tree/master/keps/sig-node/3063-dynamic-resource-allocation">kep: dynamic resource allocation</a> （下面简称DRA），也提供了一种方式（目前还是alpha），可以实现全局的资源调度、分配时能找到对应的pod。</p><p>整体逻辑如下所示，Resource Driver是用户实现资源管理逻辑，包含两部分：resource device controller负责同步<code>ResourceClaim</code>、<code>ResourceClass</code>、<code>Pod</code>等CRD资源，同时与kube-scheduler交互，进行全局的资源调度；resource kubelet plugin负责与kubelet交互，为调度到本节点Pod准备resource。</p><p><img src="/img/dynamic-resource-allocation.png" srcset="/img/loading.gif"></p><p>DRA借鉴了存储中SC、PVC的设计理念，对应的API为<code>ResourceClass</code>、<code>ResourceClaim</code>。其中<code>ResouceClass</code>巧妙的应用了CRD Ref，开发者可以定义一个CRD作为resource driver的参数配置，这样一来，一套resource driver可以服务多种<code>ResourceClass</code>。而在存储中，作为分配结果的PV，在DRA被省略，分配的结果将被记录在<code>ResourceClaimStatus</code>中。</p><div class="hljs"><pre><code class="hljs go"><span class="hljs-keyword">type</span> ResourceClass <span class="hljs-keyword">struct</span> &#123;
	...

	<span class="hljs-comment">// ParametersRef references an arbitrary separate object that may hold</span>
	<span class="hljs-comment">// parameters that will be used by the driver when allocating a</span>
	<span class="hljs-comment">// resource that uses this class. A dynamic resource driver can</span>
	<span class="hljs-comment">// distinguish between parameters stored here and and those stored in</span>
	<span class="hljs-comment">// ResourceClaimSpec.</span>
	<span class="hljs-comment">// +optional</span>
	ParametersRef *ResourceClassParametersReference
	
	...
&#125;</code></pre></div><p>dynamic resource alloncation有两种分配模式：WaitForFirstConsumer与Immediate。前者属于延迟分配，kube-scheduler先调度pod，device driver在分配资源；后者属于立即分配，先由device driver分配资源，再由kube-scheduler根据分配的结果，进行pod调度。</p><p>WaitForFirstConsumer模式下，kube-scheduler通过<code>PodSchedulingContext</code> CRD与resource driver controller进行协同调度。具体的：</p><ul><li>kube-scheduler会将Filter阶段的结果写到<code>PodSchedulingContextSpec.PotentialNodes</code>上</li><li>resource driver过滤<code>PodSchedulingContextSpec.PotentialNodes</code>，将不适合的node写到<code>ResourceClaimSchedulingStatus.UnsuitableNodes</code>上</li><li>kube-scheduler有了这些信息后，会进行<strong>尝试</strong>，将尝试的node写到<code>PodSchedulingContextSpec.SelectedNode</code>上</li><li>resource driver获取<code>PodSchedulingContextSpec.SelectedNode</code>。如果节点可以，则分配resource，将结果写入到<code>ResourceClaim</code>上，后续kube-scheduler完成调度；如果节点不可以，则更新<code>ResourceClaimSchedulingStatus.UnsuitableNodes</code>，待kube-scheduler重新尝试</li></ul><div class="hljs"><pre><code class="hljs go"><span class="hljs-comment">// PodSchedulingContextSpec describes where resources for the Pod are needed.</span>
<span class="hljs-keyword">type</span> PodSchedulingContextSpec <span class="hljs-keyword">struct</span> &#123;
	<span class="hljs-comment">// SelectedNode is the node for which allocation of ResourceClaims that</span>
	<span class="hljs-comment">// are referenced by the Pod and that use &quot;WaitForFirstConsumer&quot;</span>
	<span class="hljs-comment">// allocation is to be attempted.</span>
	SelectedNode <span class="hljs-keyword">string</span>

	<span class="hljs-comment">// PotentialNodes lists nodes where the Pod might be able to run.</span>
	<span class="hljs-comment">//</span>
	<span class="hljs-comment">// The size of this field is limited to 128. This is large enough for</span>
	<span class="hljs-comment">// many clusters. Larger clusters may need more attempts to find a node</span>
	<span class="hljs-comment">// that suits all pending resources. This may get increased in the</span>
	<span class="hljs-comment">// future, but not reduced.</span>
	<span class="hljs-comment">// +optional</span>
	PotentialNodes []<span class="hljs-keyword">string</span>
&#125;

<span class="hljs-keyword">type</span> ResourceClaimSchedulingStatus <span class="hljs-keyword">struct</span> &#123;  
<span class="hljs-comment">// Name matches the pod.spec.resourceClaims[*].Name field.// +optional  </span>
	Name <span class="hljs-keyword">string</span> 
  
<span class="hljs-comment">// UnsuitableNodes lists nodes that the ResourceClaim cannot be// allocated for.  </span>
<span class="hljs-comment">//  </span>
<span class="hljs-comment">// The size of this field is limited to 128, the same as for  </span>
<span class="hljs-comment">// PodSchedulingSpec.PotentialNodes. This may get increased in the  </span>
<span class="hljs-comment">// future, but not reduced.  </span>
<span class="hljs-comment">//  </span>
<span class="hljs-comment">// +listType=set  </span>
<span class="hljs-comment">// +optional  </span>
	UnsuitableNodes []<span class="hljs-keyword">string</span>  
&#125;</code></pre></div><p>感觉整个调度过程还是相当麻烦的。至于resource driver的实现，<a target="_blank" rel="noopener" href="https://github.com/kubernetes-sigs/dra-example-driver">kubernetes-sigs/dra-example-driver</a>打了个样，需要分别实现k8s.io/kubelet/pkg/apis/dra/v1alpha2里的<a target="_blank" rel="noopener" href="https://github.com/kubernetes/kubernetes/blob/v1.27.3/staging/src/k8s.io/kubelet/pkg/apis/dra/v1alpha2/api.pb.go#L367">NodeServer</a>，以及k8s.io/dynamic-resource-allocation/controller里的<a target="_blank" rel="noopener" href="https://github.com/kubernetes/dynamic-resource-allocation/blob/release-1.27/controller/controller.go#L56">Driver</a>。</p><p>按照DRA的方式，我们可以在Driver的<code>UnsuitableNodes()</code>里，对节点是否满足<code>PCIe switches only</code>（可以参考nccl的拓扑创建与路径判断逻辑），然后在Driver的<code>Allocate()</code>里进行RDMA与GPU的同时分配（<code>Allocate()</code>传递的参数为<code>claims []*ClaimAllocation</code>，可以进行多个分配）。</p></div><hr><div><div class="post-metas mb-3"><div class="post-meta mr-3"><i class="iconfont icon-category"></i> <a class="hover-with-bg" href="/categories/AI/">AI</a></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a class="hover-with-bg" href="/tags/Kubernetes/">Kubernetes</a></div></div><p class="note note-warning">转载请注明出处</p><div class="post-prevnext row"><article class="post-prev col-6"></article><article class="post-next col-6"> <a href="/2023/06/12/%E6%9F%A5%E8%AF%A2RDMA%E7%BD%91%E5%8D%A1%E9%80%BB%E8%BE%91Port%E4%B8%8E%E7%89%A9%E7%90%86%E8%AE%BE%E5%A4%87%E6%98%A0%E5%B0%84%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E5%BC%8F/"><span class="hidden-mobile">查询RDMA网卡逻辑Port与物理设备映射的几种方式</span> <span class="visible-mobile">下一篇</span><i class="iconfont icon-arrowright"></i></a></article></div></div></article></div></div></div><div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p><div id="tocbot"></div></div></div></div></div></main><a id="scroll-top-button" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4> <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"> <span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"> <input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div><footer class="mt-5"><div class="text-center py-3"><div> <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a><i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a></div><div class="statistics"> <span id="leancloud-site-pv-container" style="display:none">总访问量<span id="leancloud-site-pv"></span> 次</span> <span id="leancloud-site-uv-container" style="display:none">总访客数<span id="leancloud-site-uv"></span> 人</span></div></div></footer><script src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js"></script><script src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js"></script><script src="/js/debouncer.js"></script><script src="/js/main.js"></script><script src="/js/lazyload.js"></script><script defer="defer" src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js"></script><script src="/js/clipboard-use.js"></script><script defer="defer">
  (function () {
    // 查询存储的记录
    function getRecord(Counter, target) {
      return new Promise(function (resolve, reject) {
        Counter('get', '/classes/Counter?where=' + encodeURIComponent(JSON.stringify({target})))
          .then(resp => resp.json())
          .then(({results, code, error}) => {
            if (code === 401) {
              throw error;
            }
            if (results && results.length > 0) {
              var record = results[0];
              resolve(record);
            } else {
              Counter('post', '/classes/Counter', {target, time: 0})
                .then(resp => resp.json())
                .then((record, error) => {
                  if (error) {
                    throw error;
                  }
                  resolve(record);
                }).catch(error => {
                console.error('Failed to create', error);
                reject(error);
              });
            }
          }).catch((error) => {
          console.error('LeanCloud Counter Error:', error);
          reject(error);
        });
      })
    }

    // 发起自增请求
    function increment(Counter, incrArr) {
      return new Promise(function (resolve, reject) {
        Counter('post', '/batch', {
          "requests": incrArr
        }).then((res) => {
          res = res.json();
          if (res.error) {
            throw res.error;
          }
          resolve(res);
        }).catch((error) => {
          console.error('Failed to save visitor count', error);
          reject(error);
        });
      });
    }

    // 构建自增请求体
    function buildIncrement(objectId) {
      return {
        "method": "PUT",
        "path": `/1.1/classes/Counter/${ objectId }`,
        "body": {
          "time": {
            '__op': 'Increment',
            'amount': 1
          }
        }
      }
    }

    // 校验是否为有效的 UV
    function validUV() {
      var key = 'LeanCloud_UV_Flag';
      var flag = localStorage.getItem(key);
      if (flag) {
        // 距离标记小于 24 小时则不计为 UV
        if (new Date().getTime() - parseInt(flag) <= 86400000) {
          return false;
        }
      }
      localStorage.setItem(key, new Date().getTime().toString());
      return true;
    }

    function addCount(Counter) {
      var enableIncr = 'true' === 'true' && window.location.hostname !== 'localhost';
      var getterArr = [];
      var incrArr = [];

      // 请求 PV 并自增
      var pvCtn = document.querySelector('#leancloud-site-pv-container');
      if (pvCtn || enableIncr) {
        var pvGetter = getRecord(Counter, 'site-pv').then((record) => {
          incrArr.push(buildIncrement(record.objectId))
          var ele = document.querySelector('#leancloud-site-pv');
          if (ele) {
            ele.innerText = record.time + 1;
            if (pvCtn) {
              pvCtn.style.display = 'inline';
            }
          }
        });
        getterArr.push(pvGetter);
      }

      // 请求 UV 并自增
      var uvCtn = document.querySelector('#leancloud-site-uv-container');
      if (uvCtn || enableIncr) {
        var uvGetter = getRecord(Counter, 'site-uv').then((record) => {
          var vuv = validUV();
          vuv && incrArr.push(buildIncrement(record.objectId))
          var ele = document.querySelector('#leancloud-site-uv');
          if (ele) {
            ele.innerText = record.time + (vuv ? 1 : 0);
            if (uvCtn) {
              uvCtn.style.display = 'inline';
            }
          }
        });
        getterArr.push(uvGetter);
      }

      // 如果是文章，请求文章的浏览数，并自增
      if ('true' === 'true') {
        var viewCtn = document.querySelector('#leancloud-post-views-container');
        if (viewCtn || enableIncr) {
          var target = decodeURI('/2023/07/18/K8S-GPUDirect-RDMA%E5%AE%9E%E8%B7%B5%E4%B9%8B%E6%8B%93%E6%89%91%E4%BC%98%E5%8C%96/');
          var viewGetter = getRecord(Counter, target).then((record) => {
            incrArr.push(buildIncrement(record.objectId))
            if (viewCtn) {
              var ele = document.querySelector('#leancloud-post-views');
              if (ele) {
                ele.innerText = (record.time || 0) + 1;
                viewCtn.style.display = 'inline';
              }
            }
          });
          getterArr.push(viewGetter);
        }
      }

      // 如果启动计数自增，批量发起自增请求
      if (enableIncr) {
        Promise.all(getterArr).then(() => {
          incrArr.length > 0 && increment(Counter, incrArr);
        })
      }
    }

    var app_id = 'rGBkjlpYFYPq3Mztf0uHkwm2-gzGzoHsz'
    var app_key = 'IwuJ6qbGLXA8pB3qeHHjuDT3'
    var server_url = 'https://rgbkjlpy.lc-cn-n1-shared.com'

    function fetchData(api_server) {
      var Counter = (method, url, data) => {
        return fetch(`${ api_server }/1.1${ url }`, {
          method,
          headers: {
            'X-LC-Id': app_id,
            'X-LC-Key': app_key,
            'Content-Type': 'application/json',
          },
          body: JSON.stringify(data)
        });
      };

      addCount(Counter);
    }

    var api_server = app_id.slice(-9) !== '-MdYXbMMI' ? server_url : `https://${ app_id.slice(0, 8).toLowerCase() }.api.lncldglobal.com`;

    if (api_server) {
      fetchData(api_server);
    } else {
      fetch('https://app-router.leancloud.cn/2/route?appId=' + app_id)
        .then(resp => resp.json())
        .then(({api_server}) => {
          fetchData('https://' + api_server);
        });
    }
  })();
</script><script src="https://cdn.staticfile.org/tocbot/4.11.1/tocbot.min.js"></script><script>$(document).ready(function(){var t=$("#board-ctn").offset().top;tocbot.init({tocSelector:"#tocbot",contentSelector:"#post-body",headingSelector:"h1,h2,h3,h4,h5,h6",linkClass:"tocbot-link",activeLinkClass:"tocbot-active-link",listClass:"tocbot-list",isCollapsedClass:"tocbot-is-collapsed",collapsibleClass:"tocbot-is-collapsible",collapseDepth:0,scrollSmooth:!0,headingsOffset:-t}),0<$(".toc-list-item").length&&$("#toc").css("visibility","visible")})</script><script src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js"></script><script>
    anchors.options = {
      placement: "right",
      visible: "hover",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script><script src="/js/local-search.js"></script><script>var path="/local-search.xml",inputArea=document.querySelector("#local-search-input");inputArea.onclick=function(){searchFunc(path,"local-search-input","local-search-result"),this.onclick=null}</script><script src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js"></script><link rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css"><script>$("#post img:not(.no-zoom img, img[no-zoom]), img[zoom]").each(function(){var t=document.createElement("a");$(t).attr("data-fancybox","images"),$(t).attr("href",$(this).attr("src")),$(this).wrap(t)})</script></body></html>